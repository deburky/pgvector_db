{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL with pgvector for Embedding Storage\n",
    "\n",
    "[**`pgvector`**](https://github.com/pgvector/pgvector) is an open-source PostgreSQL extension for storing and searching ML-generated embeddings. It supports **exact and approximate nearest neighbor (ANN) search**, seamlessly integrating with PostgreSQL's indexing and querying features.\n",
    "\n",
    "### üöÄ Why Use PostgreSQL for Vector Storage?\n",
    "\n",
    "1Ô∏è‚É£ **Unified Data Store** ‚Äì Store both **vector embeddings and structured data** (metadata, reports, categories) in one place, reducing system complexity.  \n",
    "2Ô∏è‚É£ **Enterprise-Grade Reliability** ‚Äì Benefit from **ACID compliance, backups, replication, and security features** proven over 30+ years.  \n",
    "3Ô∏è‚É£ **Rich SQL Querying** ‚Äì Run **powerful joins, filters, and aggregations** across relational and vector data without additional databases.  \n",
    "4Ô∏è‚É£ **Scalable & Performant** ‚Äì Handle **large-scale embeddings** efficiently with PostgreSQL‚Äôs indexing (`IVFFLAT`, `HNSW`).  \n",
    "5Ô∏è‚É£ **Open Source & Cost-Effective** ‚Äì No vendor lock-in, strong community support, and the flexibility of customization.   \n",
    "\n",
    "### üõ†Ô∏è Key Benefits for AI & Analytics Workloads\n",
    "‚úÖ **Fast similarity search** ‚Äì Retrieve the most relevant documents, reports, or features using efficient ANN search.  \n",
    "‚úÖ **Feature store for ML** ‚Äì Store embeddings alongside **metadata (ASINs, timestamps, categories, user preferences)** to enhance ML models.  \n",
    "‚úÖ **Low-latency retrieval** ‚Äì Supports **real-time AI inference** via fast SQL queries, making it ideal for recommendation systems & search.  \n",
    "‚úÖ **Works with existing tools** ‚Äì Seamlessly integrates with **Python, Pandas, SQL-based analytics, and BI tools**.  \n",
    "\n",
    "üìå **Bottom line:** `pgvector` turns PostgreSQL into a **powerful, low-latency, AI-ready vector store** while keeping your architecture simple and scalable.\n",
    "\n",
    "Author: https://www.github.com/deburky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))  # Ensure src/ is in Python path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define local path\n",
    "local_model_path = \"../models/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Load and save model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model.save(local_model_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to {local_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pgvector_db.utils import time_it\n",
    "from pgvector_db.generate_embeddings import EmbeddingGenerator\n",
    "\n",
    "# Define local model path\n",
    "local_model_path = \"../models/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Initialize generator with batch processing\n",
    "generator = EmbeddingGenerator(\n",
    "    model_path=local_model_path,\n",
    "    model_type=\"sentence-transformers\",\n",
    "    batch_size=100,\n",
    "    device=\"mps\"\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet(\"../data/dataset_with_embeddings.parquet\")\n",
    "dataset = dataset[~dataset[\"text\"].isna()].copy()\n",
    "\n",
    "# Generate embeddings in batches\n",
    "text_samples = dataset[\"text\"].astype(str).tolist()\n",
    "\n",
    "@time_it\n",
    "def generate_embeddings(text_samples):\n",
    "    return generator.generate_embeddings(text_samples)\n",
    "\n",
    "embeddings = generate_embeddings(text_samples)\n",
    "\n",
    "# Save embeddings to Parquet\n",
    "output_path = \"../data/generated_embeddings.parquet\"\n",
    "generator.save_to_parquet(text_samples, embeddings, output_path)\n",
    "print(f\"‚úÖ Embeddings saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time streaming\n",
    "\n",
    "Here we mimic real-time streaming with Postgres. Both copy and insert give the same latency results.\n",
    "\n",
    "1. For true real-time, low-latency writes (one record at a time) ‚Üí Use `pg_insert`.\n",
    "- Best suited for event-driven ingestion.\n",
    "- Works well with Lambda, Flask API, Kafka events.\n",
    "- Simple and requires no extra Parquet conversion.\n",
    "\n",
    "2. For mini-batching (e.g., process events every few seconds/minutes) ‚Üí Use `pg_copy`.\n",
    "- More efficient for bulk inserts because PostgreSQL handles batch I/O better.\n",
    "- Reduces transaction overhead by writing multiple rows at once.\n",
    "- Ideal for batch streaming frameworks like Spark Streaming, Kinesis, or Kafka with batch intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from pgvector_db.generate_embeddings import EmbeddingGenerator\n",
    "from pgvector_db.utils import DBConfigLocal\n",
    "\n",
    "password = os.environ.get(\"PG_PASSWORD\")\n",
    "\n",
    "# Define PostgreSQL DBConfig\n",
    "db_config_realtime = DBConfigLocal(\n",
    "    db_name=\"vector_db\",\n",
    "    db_user=\"py_pg_user\",\n",
    "    db_password=password,\n",
    "    db_host=\"localhost\",\n",
    "    schema_name=\"public\",\n",
    "    table_name=\"realtime_documents\"\n",
    ")\n",
    "\n",
    "# Initialize Embedding Generator\n",
    "local_model_path = \"../models/all-MiniLM-L6-v2\"\n",
    "generator = EmbeddingGenerator(\n",
    "    model_path=local_model_path,\n",
    "    model_type=\"sentence-transformers\",\n",
    "    batch_size=100,  # Simulating real-time, so 1 at a time\n",
    "    device=\"mps\"\n",
    ")\n",
    "\n",
    "# Load dataset & prepare for streaming simulation\n",
    "path_to_data = \"../data/generated_embeddings.parquet\"\n",
    "dataset = pd.read_parquet(path_to_data)\n",
    "dataset = dataset[~dataset[\"text\"].isna()].copy()\n",
    "text_samples = dataset[\"text\"].tolist()\n",
    "\n",
    "# Simulate incoming data (random streaming)\n",
    "streaming_batch = random.sample(text_samples, 100)  # Select 5 random texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pgvector_db.utils import time_it\n",
    "from pgvector_db.pg_insert import pg_insert\n",
    "\n",
    "# Process streaming text with INSERT\n",
    "insert_latencies = []\n",
    "\n",
    "@time_it\n",
    "def process_streaming_batch(streaming_batch):\n",
    "    \"\"\"Processes a batch of streaming text data and inserts embeddings into PostgreSQL.\"\"\"\n",
    "    for text in streaming_batch:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Generate embeddings for this text\n",
    "        embedding = generator.generate_embeddings([text])[0]  # Extract 1D array\n",
    "\n",
    "        # Convert to list and wrap inside DataFrame\n",
    "        df = pd.DataFrame({\"text\": [text], \"embedding\": [embedding.tolist()]})\n",
    "\n",
    "        # Insert into PostgreSQL\n",
    "        pg_insert(df, db_config_realtime, batch_size=1)\n",
    "\n",
    "        latency = time.time() - start_time\n",
    "        insert_latencies.append(latency)\n",
    "\n",
    "# Run streaming\n",
    "process_streaming_batch(streaming_batch)\n",
    "\n",
    "print(f\"‚úÖ Avg Insert Latency: {np.mean(insert_latencies):.4f} sec per record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pgvector_db.utils import time_it\n",
    "from pgvector_db.pg_copy import pg_copy\n",
    "\n",
    "# Process streaming text with COPY\n",
    "copy_latencies = []\n",
    "\n",
    "@time_it\n",
    "def process_streaming_batch(streaming_batch):\n",
    "    \"\"\"Processes a batch of streaming text data and copy embeddings into PostgreSQL.\"\"\"\n",
    "    for text in streaming_batch:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Generate embeddings for this text\n",
    "        embedding = generator.generate_embeddings([text])[0]  # Extract 1D array\n",
    "\n",
    "        # Convert to list and wrap inside DataFrame\n",
    "        df = pd.DataFrame({\"text\": [text], \"embedding\": [embedding.tolist()]})\n",
    "\n",
    "        # Copy into PostgreSQL\n",
    "        pg_copy(df, db_config_realtime)\n",
    "\n",
    "        latency = time.time() - start_time\n",
    "        copy_latencies.append(latency)\n",
    "\n",
    "# Run streaming\n",
    "process_streaming_batch(streaming_batch)\n",
    "\n",
    "print(f\"‚úÖ Avg Copy Latency: {np.mean(insert_latencies):.4f} sec per record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_data = \"../data/generated_embeddings.parquet\"\n",
    "dataset = pd.read_parquet(path_to_data)\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert workflow\n",
    "\n",
    "When you send an `INSERT` command to PostgreSQL, the server processes it in several steps:\n",
    "\n",
    "1Ô∏è‚É£ **Query Parsing & Validation** ‚Äì PostgreSQL analyzes the query structure, verifies the table and columns exist, and checks user permissions.  \n",
    "2Ô∏è‚É£ **Data Type & Constraint Checks** ‚Äì Ensures values match column types and adhere to constraints (e.g., `NOT NULL`, `UNIQUE`).  \n",
    "3Ô∏è‚É£ **Row Insertion** ‚Äì Writes the new row into shared buffers and updates internal data structures.  \n",
    "4Ô∏è‚É£ **Index Updates** ‚Äì If indexes exist, PostgreSQL updates them accordingly.  \n",
    "5Ô∏è‚É£ **Transaction Handling** ‚Äì The operation runs within a transaction, ensuring changes are either **committed** or **rolled back** on failure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pgvector_db.pg_insert import pg_insert\n",
    "from pgvector_db.utils import DBConfigLocal\n",
    "\n",
    "# Retrieve password from the environment\n",
    "password = os.environ.get('PG_PASSWORD')\n",
    "\n",
    "# Convert DataFrame embeddings (numpy arrays) into lists for PostgreSQL\n",
    "dataset[\"embedding\"] = dataset[\"embeddings\"].apply(lambda x: np.array(x).tolist())\n",
    "\n",
    "# Use Local DBConfig for Local PostgreSQL\n",
    "db_config_local = DBConfigLocal(\n",
    "    db_name=\"vector_db\",\n",
    "    db_user=\"py_pg_user\",\n",
    "    db_password=password,\n",
    "    db_host=\"localhost\",\n",
    "    schema_name=\"public\",\n",
    "    table_name=\"documents\"\n",
    ")\n",
    "\n",
    "# Run batch insert for Local\n",
    "pg_insert(dataset, db_config_local, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy workflow\n",
    "\n",
    "When you execute a `COPY` command in PostgreSQL, the server processes it in the following steps:\n",
    "\n",
    "1Ô∏è‚É£ **Query Parsing & Validation** ‚Äì PostgreSQL verifies the command structure, ensures the target table exists, and checks user permissions.  \n",
    "2Ô∏è‚É£ **Data Formatting & Parsing** ‚Äì Reads data from a file or standard input (`STDIN`), interpreting CSV, binary, or text formats.  \n",
    "3Ô∏è‚É£ **Batch Data Insertion** ‚Äì Loads multiple rows at once, bypassing individual `INSERT` overhead for faster ingestion.  \n",
    "4Ô∏è‚É£ **Constraint & Type Checks** ‚Äì Validates data against column types, constraints (`NOT NULL`, `CHECK`), and primary/foreign keys.  \n",
    "5Ô∏è‚É£ **Index & WAL Handling** ‚Äì Updates indexes if present and minimizes **WAL (Write-Ahead Logging)** overhead for performance.  \n",
    "6Ô∏è‚É£ **Transaction Control** ‚Äì If `COPY` is part of a transaction, changes can be **committed** or **rolled back** on failure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pgvector_db.pg_copy import pg_copy\n",
    "from pgvector_db.utils import DBConfigLocal\n",
    "\n",
    "# Retrieve password from the environment\n",
    "password = os.environ.get('PG_PASSWORD')\n",
    "\n",
    "# Convert DataFrame embeddings (numpy arrays) into lists for PostgreSQL\n",
    "dataset[\"embedding\"] = dataset[\"embeddings\"].apply(lambda x: np.array(x).tolist())\n",
    "\n",
    "# Use Local DBConfig for Local PostgreSQL\n",
    "db_config_local = DBConfigLocal(\n",
    "    db_name=\"vector_db\",\n",
    "    db_user=\"py_pg_user\",\n",
    "    db_password=password,\n",
    "    db_host=\"localhost\",\n",
    "    schema_name=\"public\",\n",
    "    table_name=\"documents\"\n",
    ")\n",
    "\n",
    "# Run copy for Local\n",
    "pg_copy(dataset, db_config_local)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgvector-db-WI9sN5Eu-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
